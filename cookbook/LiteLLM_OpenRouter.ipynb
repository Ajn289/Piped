{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LiteLLM OpenRouter Cookbook"
      ],
      "metadata": {
        "id": "iFEmsVJI_2BR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cBlUhCEP_xj4",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6262fa79-03f0-4039-d847-93387e7bd2db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting litellm\n",
            "  Downloading litellm-1.60.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm) (3.11.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm) (8.1.8)\n",
            "Collecting httpx<0.28.0,>=0.23.0 (from litellm)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (8.6.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm) (3.1.5)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.55.3 in /usr/local/lib/python3.11/dist-packages (from litellm) (1.59.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (2.10.6)\n",
            "Collecting python-dotenv>=0.2.0 (from litellm)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting tiktoken>=0.7.0 (from litellm)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm) (0.21.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.23.0->litellm) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.23.0->litellm) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.23.0->litellm) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.23.0->litellm) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.23.0->litellm) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.22.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.55.3->litellm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.55.3->litellm) (0.8.2)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.55.3->litellm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.55.3->litellm) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.27.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.18.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm) (0.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.3.0)\n",
            "Downloading litellm-1.60.0-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, tiktoken, httpx, litellm\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "Successfully installed httpx-0.27.2 litellm-1.60.0 python-dotenv-1.0.1 tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install litellm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['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'] = \"\""
      ],
      "metadata": {
        "id": "p-MQqWOT_1a7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from litellm import completion\n",
        "response = completion(\n",
        "            model=\"openrouter/google/palm-2-chat-bison\",\n",
        "            messages=[{\"role\": \"user\", \"content\": \"write code for saying hi\"}]\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze8JqMqWAARO",
        "outputId": "f2c613e4-6d98-4a51-c51e-7f0eecd2d14a",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelResponse(id='gen-1738560481-HRgqgduezl0GzKHYCKKw', created=1738560481, model='openrouter/google/palm-2-chat-bison', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=' ```python\\ndef say_hi(name):\\n  \"\"\"Says hello to the person with the given name.\\n\\n  Args:\\n    name: The name of the person to say hello to.\\n\\n  Returns:\\n    A string containing the greeting.\\n  \"\"\"\\n\\n  return \"Hello, \" + name + \"!\"\\n```', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, refusal=None))], usage=Usage(completion_tokens=61, prompt_tokens=12, total_tokens=73, completion_tokens_details=None, prompt_tokens_details=None), service_tier=None, provider='Google')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"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\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "3uq2xljxR4fR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = completion(\n",
        "            model=\"openrouter/anthropic/claude-2\",\n",
        "            messages=[{\"role\": \"user\", \"content\": \"write code for saying hi\"}]\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LnhELrnAM_J",
        "outputId": "c2dc54af-4834-4d28-be93-88eef74dee3e",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelResponse(id='gen-1738560488-YDUZ8sx8IVl6B9L6Mr7m', created=1738560488, model='openrouter/anthropic/claude-2', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Here is some Python code for saying \"hi\":\\n\\n```python\\nprint(\"Hi\")\\n```\\n\\nThis simply prints the string \"Hi\" to the console output.\\n\\nA few other ways to say hi:\\n\\n```python \\nprint(\"Hello\")\\n\\nprint(\"Hey there!\")\\n\\nprint(\"Hi there!\")\\n\\nprint(\"Greetings!\")\\n```\\n\\nYou can customize the message by assigning it to a variable first:\\n\\n```python\\ngreeting = \"Hi friend!\"\\nprint(greeting)\\n\\nname = \"John\"\\nprint(f\"Hi {name}!\") \\n```\\n\\nOr you can prompt for user input:\\n\\n```python\\nname = input(\"Enter your name: \")\\nprint(f\"Hello {name}!\")\\n```\\n\\nSo in just a line or two of Python you can print out a greeting. You can customize the message, include variables, or get user input to personalize it further.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, refusal=None))], usage=Usage(completion_tokens=209, prompt_tokens=14, total_tokens=223, completion_tokens_details=None, prompt_tokens_details=None), service_tier=None, provider='Anthropic')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = completion(\n",
        "            model=\"openrouter/meta-llama/llama-2-70b-chat\",\n",
        "            messages=[{\"role\": \"user\", \"content\": \"write code for saying hi\"}]\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJBOUYdwCEn1",
        "outputId": "5642d809-0fc2-4ffe-ab49-e8a9eec82b50",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelResponse(id='gen-1738560529-yXIi7Dn3Q7l8wPssIUbc', created=1738560529, model='openrouter/meta-llama/llama-2-70b-chat', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='hello.gif\\n\\nyoure welcome.gif\\n\\nimage of tails.gif\\n\\\\end{code}\\n\\n', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, refusal=None))], usage=Usage(completion_tokens=27, prompt_tokens=43, total_tokens=70, completion_tokens_details=None, prompt_tokens_details=None), service_tier=None, provider='Together')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}